{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandtun\u001b[0m (\u001b[33mobuchii\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt4o</th>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>2.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4omini</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4turbo</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>8.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>17.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>0.4320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model    price\n",
       "index                                 \n",
       "gpt4o       gpt-4o-2024-08-06   2.8800\n",
       "gpt4omini         gpt-4o-mini   0.1728\n",
       "gpt4turbo         gpt-4-turbo   8.6400\n",
       "gpt4                    gpt-4  17.2800\n",
       "gpt35      gpt-3.5-turbo-0125   0.4320"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MODEL_LIST = pd.read_csv(\"model_list.csv\").set_index(\"index\")\n",
    "MODEL_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "# Загрузка переменных окружения из .env файла\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class GPT4SpellChecker:\n",
    "    \"\"\"\n",
    "    Класс для проверки орфографии и пунктуации с использованием GPT-4 через OpenAI API.\n",
    "\n",
    "    Attributes:\n",
    "        api_key (str): Ключ для доступа к API OpenAI.\n",
    "    \"\"\"\n",
    "\n",
    "    BASE_URL = \"https://api.proxyapi.ru/openai/v1\"\n",
    "\n",
    "    SYSTEM_PROMPT = \"Ты опытный корректор текста.\"\n",
    "\n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "Ты выступаешь в роли профессионального корректора текста на русском языке с многолетним опытом. Твоя задача состоит в следующем:\n",
    "\n",
    "Проанализировать и исправить все орфографические, грамматические и пунктуационные ошибки в тексте, сохраняя исходный смысл и стиль.\n",
    "Для каждой ошибки:\n",
    "Определи её точное местоположение, указав индекс начала ошибки.\n",
    "Укажи текст ошибки.\n",
    "Предложи один или несколько вариантов исправления.\n",
    "Объясни, почему это ошибка, и укажи её тип (орфографическая, грамматическая, пунктуационная).\n",
    "Верни результат в формате JSON, где для каждой ошибки укажи:\n",
    "\"index\": индекс начала ошибки в тексте,\n",
    "\"error\": исходный текст с ошибкой,\n",
    "\"suggestions\": список предложенных исправлений,\n",
    "\"message\": краткое описание ошибки и её типа.\n",
    "После исправлений предоставь исправленный текст.\n",
    "\n",
    "Пример 1: Оригинальный текст: \"Я обожаю учится, это делаэт меня лучше!\" Результат:\n",
    "\n",
    "{\n",
    "    \"corrections\": [\n",
    "        {\n",
    "            \"index\": 9,\n",
    "            \"error\": \"учится\",\n",
    "            \"suggestions\": [\"учиться\"],\n",
    "            \"message\": \"Грамматическая ошибка: инфинитив 'учиться' должен использоваться в данном контексте.\"\n",
    "        },\n",
    "        {\n",
    "            \"index\": 19,\n",
    "            \"error\": \"делаэт\",\n",
    "            \"suggestions\": [\"делает\"],\n",
    "            \"message\": \"Орфографическая ошибка: глагол 'делает' пишется через 'е'.\"\n",
    "        }\n",
    "    ],\n",
    "    \"corrected_text\": \"Я обожаю учиться, это делает меня лучше!\"\n",
    "}\n",
    "Пример 2: Оригинальный текст: \"Пока я небыл дома, ктото пришел.\" Результат:\n",
    "\n",
    "{\n",
    "    \"corrections\": [\n",
    "        {\n",
    "            \"index\": 8,\n",
    "            \"error\": \"небыл\",\n",
    "            \"suggestions\": [\"не был\"],\n",
    "            \"message\": \"Грамматическая ошибка: частица 'не' пишется отдельно от глагола.\"\n",
    "        },\n",
    "        {\n",
    "            \"index\": 18,\n",
    "            \"error\": \"ктото\",\n",
    "            \"suggestions\": [\"кто-то\"],\n",
    "            \"message\": \"Орфографическая ошибка: слово 'кто-то' пишется через дефис.\"\n",
    "        }\n",
    "    ],\n",
    "    \"corrected_text\": \"Пока я не был дома, кто-то пришел.\"\n",
    "}\n",
    "Используй этот формат и исправь следующий текст: \"%s\"\n",
    "    \"\"\"\n",
    "    corrections_split_prefix = \"2. Список исправлений:\"\n",
    "\n",
    "    def __init__(self, model_name: str, temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Инициализация модели GPT-4 через OpenAI API.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Название модели, по умолчанию используется GPT-4.\n",
    "            temperature (float): Температура модели для управления степенью творчества.\n",
    "        \"\"\"\n",
    "        # Получение API ключа из переменной окружения\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"API ключ OpenAI не найден в переменных окружения.\")\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=self.BASE_URL,\n",
    "        )\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def predict_verbose(\n",
    "        self, text: str\n",
    "    ) -> Tuple[List[Dict[str, Union[str, float]]], str]:\n",
    "        \"\"\"\n",
    "        Возвращает исправленный текст и список всех предложенных исправлений с типом ошибки и уверенностью.\n",
    "\n",
    "        Args:\n",
    "            text (str): Входной текст для проверки.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[Dict[str, Union[str, float]]], str]: Исправленный текст и список всех предложенных исправлений.\n",
    "        \"\"\"\n",
    "        prompt = self._create_prompt(text)\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "\n",
    "        # Получаем ответ от модели\n",
    "        result = response.choices[0].message.content\n",
    "\n",
    "        r = self._process_gpt4_output(result)\n",
    "        return r[\"corrections\"], r[\"corrected_text\"]\n",
    "\n",
    "    def _create_prompt(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Создает промпт для GPT-4, чтобы обеспечить максимально качественное исправление текста с уверенностью и типом ошибки.\n",
    "\n",
    "        Args:\n",
    "            text (str): Входной текст для проверки.\n",
    "\n",
    "        Returns:\n",
    "            str: Промпт для модели GPT-4.\n",
    "        \"\"\"\n",
    "        return self.PROMPT_TEMPLATE % text\n",
    "\n",
    "    def _process_gpt4_output(\n",
    "        self, result: str\n",
    "    ) -> Dict[str, Union[List[Dict[str, str]], str]]:\n",
    "        \"\"\"\n",
    "        Обрабатывает результат, полученный от модели GPT-4.\n",
    "\n",
    "        Args:\n",
    "            result (str): Результат, возвращаемый GPT-4.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Union[List[Dict[str, str]], str]]: Словарь с исправлениями и исправленным текстом.\n",
    "        \"\"\"\n",
    "        # Ожидаем, что GPT-4 вернет результат в формате JSON\n",
    "        try:\n",
    "            result_json = eval(result)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Ошибка при парсинге ответа: {e}\")\n",
    "\n",
    "        return result_json\n",
    "\n",
    "    def predict(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Возвращает исправленный текст.\n",
    "\n",
    "        Args:\n",
    "            text (str): Входной текст для проверки.\n",
    "\n",
    "        Returns:\n",
    "            str: Исправленный текст.\n",
    "        \"\"\"\n",
    "        _, corrected_text = self.predict_verbose(text)\n",
    "        return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt4omini\"\n",
    "m = GPT4SpellChecker(model_name=MODEL_LIST.loc[model_name].model, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = m.predict_verbose(\"Превет я Ондрей\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'index': 0,\n",
       "   'error': 'Превет',\n",
       "   'suggestions': ['Привет'],\n",
       "   'message': \"Орфографическая ошибка: слово 'Привет' пишется с буквой 'и'.\"},\n",
       "  {'index': 6,\n",
       "   'error': 'Ондрей',\n",
       "   'suggestions': ['Андрей'],\n",
       "   'message': \"Орфографическая ошибка: имя 'Андрей' пишется с буквой 'А'.\"}],\n",
       " 'Привет я Андрей')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"gpt_spellers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lang_check\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the latest cached version of the dataset since ai-forever/spellcheck_benchmark couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'RUSpellRU' at C:\\Users\\Андрей Т\\.cache\\huggingface\\datasets\\ai-forever___spellcheck_benchmark\\RUSpellRU\\0.0.1\\3395aa540689e4393c3e18d063e73a5b99d7f047 (last modified on Mon Jun 17 00:55:50 2024).\n"
     ]
    }
   ],
   "source": [
    "from src.datasets import load_datasets\n",
    "\n",
    "orpho_dataset, punct_dataset = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head(dataset, n=5):\n",
    "    return dataset.select(range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from src.model_scorers import WandbSageModelScorer\n",
    "\n",
    "\n",
    "def _score_model(mode: str, dataset, model_name: str, temperature: float):\n",
    "    sms = WandbSageModelScorer(dataset, project=PROJECT_NAME, run_suffix=mode)\n",
    "    model = GPT4SpellChecker(model_name, temperature=temperature)\n",
    "    scoring_final_result, explanation = sms.score_explain(\n",
    "        model, metrics=[\"errant\", \"ruspelleval\"]\n",
    "    )\n",
    "    wandb.run.summary[\"temperature\"] = temperature\n",
    "    wandb.run.summary[\"prompt\"] = model.PROMPT_TEMPLATE\n",
    "    print(f\"{model_name} ({mode}):\")\n",
    "    print(scoring_final_result, explanation, sep=\"\\n\\n\\n\")\n",
    "    return scoring_final_result, explanation\n",
    "\n",
    "\n",
    "def score(mode: Literal[\"orpho\"] | Literal[\"punct\"], model_name, temperature: float):\n",
    "    if mode == \"orpho\":\n",
    "        _score_model(\n",
    "            mode=\"orpho\",\n",
    "            dataset=head(orpho_dataset[\"test\"]),\n",
    "            model_name=model_name,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "    elif mode == \"punct\":\n",
    "        _score_model(\n",
    "            mode=\"punct\",\n",
    "            dataset=head(punct_dataset[\"test\"]),\n",
    "            model_name=model_name,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"No such mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование: орфография и пунктуация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\lang_check\\experiments\\001-model_comparison\\wandb\\run-20240827_212249-wto00gi5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/obuchii/gpt_spellers/runs/wto00gi5' target=\"_blank\">exalted-hill-3</a></strong> to <a href='https://wandb.ai/obuchii/gpt_spellers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/obuchii/gpt_spellers' target=\"_blank\">https://wandb.ai/obuchii/gpt_spellers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/obuchii/gpt_spellers/runs/wto00gi5' target=\"_blank\">https://wandb.ai/obuchii/gpt_spellers/runs/wto00gi5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.77s/it]\n",
      "Calculating errant metric: 100%|██████████| 5/5 [00:00<00:00, 13.41it/s]\n",
      "Calculating words metric: 100%|██████████| 5/5 [00:00<00:00, 238.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini (orpho):\n",
      "{'SPELL_Precision': 25.0, 'SPELL_Recall': 60.0, 'SPELL_F1': 35.29, 'PUNCT_Precision': 0.0, 'PUNCT_Recall': 100.0, 'PUNCT_F1': 0.0, 'CASE_Precision': 0.0, 'CASE_Recall': 100.0, 'CASE_F1': 0.0, 'YO_Precision': 100.0, 'YO_Recall': 100.0, 'YO_F1': 100.0, 'Precision': 27.27, 'Recall': 60.0, 'F1': 37.5}\n",
      "\n",
      "\n",
      "                                              Source  \\\n",
      "0     ﻿есть у вас оформленый и подписаный мною заказ   \n",
      "1  вот в инете откапал такую интеерсную статейку ...   \n",
      "2  я на всю жизнь запомню свое первое купание в з...   \n",
      "3  думаем что не ошибемся если скажем что выставк...   \n",
      "4  судьба человека может складываться очень разно...   \n",
      "\n",
      "                                               Truth  \\\n",
      "0   ﻿есть у вас оформленный и подписанный мною заказ   \n",
      "1  вот в инете откопал такую интересную статейку ...   \n",
      "2  я на всю жизнь запомню свое первое купание в з...   \n",
      "3  думаем что не ошибемся если скажем что выставк...   \n",
      "4  судьба человека может складываться очень разно...   \n",
      "\n",
      "                                        Model_result  Model_is_correct  \n",
      "0   Есть у вас оформленный и подписанный мною заказ.             False  \n",
      "1  Вот в интернете откапал такую интересную стать...             False  \n",
      "2  Я на всю жизнь запомню свое первое купание в з...             False  \n",
      "3  Думаем, что не ошибемся, если скажем, что выст...             False  \n",
      "4  Судьба человека может складываться очень разно...             False  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wto00gi5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>prompt</td><td>\n",
       "Ты выступаешь в рол...</td></tr><tr><td>temperature</td><td>0.2</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-hill-3</strong> at: <a href='https://wandb.ai/obuchii/gpt_spellers/runs/wto00gi5' target=\"_blank\">https://wandb.ai/obuchii/gpt_spellers/runs/wto00gi5</a><br/> View project at: <a href='https://wandb.ai/obuchii/gpt_spellers' target=\"_blank\">https://wandb.ai/obuchii/gpt_spellers</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240827_212249-wto00gi5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wto00gi5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\lang_check\\experiments\\001-model_comparison\\wandb\\run-20240827_212311-0aytlvnm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/obuchii/gpt_spellers/runs/0aytlvnm' target=\"_blank\">celestial-flower-4</a></strong> to <a href='https://wandb.ai/obuchii/gpt_spellers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/obuchii/gpt_spellers' target=\"_blank\">https://wandb.ai/obuchii/gpt_spellers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/obuchii/gpt_spellers/runs/0aytlvnm' target=\"_blank\">https://wandb.ai/obuchii/gpt_spellers/runs/0aytlvnm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.92s/it]\n",
      "Calculating errant metric: 100%|██████████| 5/5 [00:00<00:00, 27.62it/s]\n",
      "Calculating words metric: 100%|██████████| 5/5 [00:00<00:00, 500.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini (punct):\n",
      "{'CASE_Precision': 100.0, 'CASE_Recall': 80.0, 'CASE_F1': 88.89, 'SPELL_Precision': 56.25, 'SPELL_Recall': 75.0, 'SPELL_F1': 64.29, 'PUNCT_Precision': 80.0, 'PUNCT_Recall': 72.73, 'PUNCT_F1': 76.19, 'YO_Precision': 100.0, 'YO_Recall': 0.0, 'YO_F1': 0.0, 'Precision': 60.0, 'Recall': 75.0, 'F1': 66.67}\n",
      "\n",
      "\n",
      "                                              Source  \\\n",
      "0  а так хочеться что-то мочь менять в этом мире ...   \n",
      "1  давольно милый и летом и зимой обогреваемый те...   \n",
      "2  бывают такие моменты когда хочеться зделать чт...   \n",
      "3     ﻿есть у вас оформленый и подписаный мною заказ   \n",
      "4  вот в инете откапал такую интеерсную статейку ...   \n",
      "\n",
      "                                               Truth  \\\n",
      "0  А так хочется что-то мочь менять в этом мире: ...   \n",
      "1  Довольно милый, и летом, и зимой обогреваемый ...   \n",
      "2  Бывают такие моменты, когда хочется сделать чт...   \n",
      "3  ﻿Есть у вас оформленный и подписанный мною заказ?   \n",
      "4  Вот в инете откопал такую интересную статейку,...   \n",
      "\n",
      "                                        Model_result  Model_is_correct  \n",
      "0  А так хочется что-то уметь менять в этом мире,...             False  \n",
      "1  Довольно милый и летом, и зимой обогреваемый т...             False  \n",
      "2  Бывают такие моменты, когда хочется сделать чт...              True  \n",
      "3   Есть у вас оформленный и подписанный мною заказ.             False  \n",
      "4  Вот в интернете откапал такую интересную стать...             False  \n"
     ]
    }
   ],
   "source": [
    "for model_name in [\"gpt-4o-mini\"]:\n",
    "    score(\"orpho\", model_name, temperature=0.2)\n",
    "    score(\"punct\", model_name, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>prompt</td><td>\n",
       "Ты выступаешь в рол...</td></tr><tr><td>temperature</td><td>0.2</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-flower-4</strong> at: <a href='https://wandb.ai/obuchii/gpt_spellers/runs/0aytlvnm' target=\"_blank\">https://wandb.ai/obuchii/gpt_spellers/runs/0aytlvnm</a><br/> View project at: <a href='https://wandb.ai/obuchii/gpt_spellers' target=\"_blank\">https://wandb.ai/obuchii/gpt_spellers</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240827_212311-0aytlvnm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:\n",
    "\n",
    "1. Попросить модель выводить только исправленный текст - сэкономим на токенах, но потеряем в качестве\n",
    "2. Сократить систем промпт и юзер промпт\n",
    "3. Менять местами систем промпт и юзер промпт, экспериментировать с гиперпараметрами\n",
    "4. **Тестировать модели только на датасете punct (потому что орф ошибки он тоже содержит) - для экономии токенов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
